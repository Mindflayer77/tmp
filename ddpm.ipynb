{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele dyfuzyjne (Denoising Diffusion Probabilistic Models)\n",
    "## Wstęp\n",
    "Modele dyfuzyjne to rodzina modeli generatywnych, które wykorzystują proces stopniowego zaszumiania próbki wejściowej (na przykład obrazu) w celu wyuczenia sieci neuronowej procesu odwrotnego - czyli usuwania szumu. Proces generowania startuje z czystego szumu, który sieć stopniowo stara się usunąć, co w konsekwencji prowadzi do wygenerowania zupełnie nowej próbki z modelowanego rozkładu. Proces zaszumiania nosi nazwę **procesu dyfuzji w przód** (forward diffusion process), a proces usuwania szumu z wykorzystaniem sieci to **proces dyfuzji wstecz** (reverse diffusion process).\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"imgs/diffusion_abstract.png\" width=\"800\"/>\n",
    "</p>\n",
    "Generowanie nowych próbek składa się z wielu (nawet tysiąca) kroków odszumiających, co oznacza tysiąc przejść przez sieć. Wynik każdego z tych kroków możemy rozpatrywać jako zmienną losową, a ponieważ przejścia międzi nimi są zależne tylko od poprzedniego stanu (własność Markowa), to cały proces można opisać jako łańcuch Markowa. \n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"imgs/markov_chain.png\" width=\"500\"/>\n",
    "</p>\n",
    "\n",
    "## Proces dyfuzji w przód (Forward diffusion process)\n",
    "Cały proces w przód zaczyna się od czystej (niezaszumionej) próbki $x_0$ pochodzącej z rozkładu danych $q(x_0)$, który chcemy modelować. \n",
    "Możemy myśleć o $x_0$ jako o konkretnym zdjęciu, natomiast $q(x_0)$ jako o wszystkich możliwych (sensownych) zdjęciach. Proces w przód ma za zadanie \n",
    "wygenerować zaszumioną próbkę $x_t$ na podstawie oryginalnej próbki $x_0$, gdzie $t$ oznacza czas dyfuzji (ilość zaszumień). \n",
    "Im większe $t$ tym więcej szumu znajduje się w próbce $x_t$ i co za tym idzie tym mniej informacji o oryginalnej próbce $x_0$. \n",
    "Proces w przód jest tak skonstruowany, że dla pewnej liczby kroków (oznaczanej jako $T$ - zazwyczaj $T = 1000$) próbka $x_T$ jest nierozróżnialna od czystego szumu $\\mathcal{N}(0, 1)$. Innymi słowy rozkład $\\mathcal{N}(0, 1)$ jest rozkładem stacjonarnym łancuchu Markova opisującego proces w przód.\n",
    "\n",
    "Proces w przód definiujemy poprzez \n",
    "$$ q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t \\mathbb{I}), \\tag{1} $$\n",
    "gdzie $x_{t-1}$ to stan poprzedni, natomiast $\\beta_t$ to tzw. *noise scheduler*, który określa siłę zaszumienia w kroku $t$. Wartości $\\beta_t$ są zazwyczaj niewielkie (np. $0.01$), co sprawia, że pojedynczy krok niewiele zmienia wygląd próbki $x_{t-1}$, jednak nałożenie na siebie wielu takich kroków (np. 1000) skutkuje stopniowym usunięciem całej informacji próbki $x_0$ na rzecz szumu. We wzorze widzimy także, że poprzednia próbka zostaje delikatnie zmniejszona (ponieważ $\\sqrt{1 - \\beta_t}$ jest nieco mniejsze niż 1), co powoduje, że wariancja nie eksploduje do nieskończoności podczas dokładaniu szumu, a dąży do 1 (tzw. Variance Preserving, VP) i dzięki temu rozkładem stacjonarnym łańcucha Markova procesu w przód jest $\\mathcal{N}(0, 1)$.\n",
    "\n",
    "Przy tak zdefiniowanym procesie, jesteśmy w stanie otrzymać dowolne zaszumienie próbki $x_0$ poprzez wykonanie odpowiedniej liczby kroków w przód\n",
    "$$ q(x_{1:T} | x_0) = \\prod_{t=1}^{T} q(x_t | x_{t-1}). \\tag{2}$$\n",
    "Wielokrotne zaszumianie jest jednak kosztowne obliczeniowo, dlatego w praktyce korzysta się ze sztuczki pozwalającej otrzymać dowolny stan $x_t$ przy użyciu tylko jednego zaszumienia. W tym celu definiuje się zmienne pomocnicze\n",
    "$$ \\alpha_t = 1 - \\beta_t, \\qquad \\bar{\\alpha}_t = \\prod_{i=1}^{t} \\alpha_i. \\tag{3} $$\n",
    "Przy wykorzystaniu tych definicji, otrzymujemy\n",
    "$$ q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1 - \\bar{\\alpha}_t) \\mathbb{I}), \\tag{4} $$\n",
    "które jest równoważne z wykonaniem $t$ razy równania (1). Wyprowadzenie wzoru (4) możecie znaleźć w [blogu](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/).\n",
    "\n",
    "## Proces dyfuzji wstecz (Reverse diffusion process)\n",
    "Potrafiąc odwracać proces w przód, potrafilibyśmy generować nowe próbki z modelowanego rozkładu danych. \n",
    "Niestety w praktyce, mimo, że rozkład $q(x_t | x_{t-1})$ jest prosty, to rozkład a posteriori $q(x_{t-1} | x_t)$ jest niemożliwy do policzenia.\n",
    "Intuicyjnie ma to sens - nie znając rozładu danych $q(x_0)$, nie jesteśmy w stanie opisać wzorem mniej zaszumionej wersji $x_t$.\n",
    "Mimo, że posterior $q(x_{t-1} | x_t)$ nie jest znany, to gdy dokonamy dodatkowego warunkowania czystą próbką $x_0$, rozkład $q(x_{t-1} | x_t, x_0)$ staje się możliwy do policzenia stosując twierdzenie Bayesa\n",
    "$$ q(x_{t-1} | x_t, x_0) = \\frac{q(x_t | x_{t-1}, x_0) q(x_{t-1} | x_0)}{q(x_t | x_0)}. \\tag{5} $$\n",
    "Jak widać, wszystkie składniki w powyższym wzorze odnoszą się do wcześniej zdefiniowanego procesu dyfuzji w przód i są znane (równania (1) i (4)). \n",
    "Gdy wszystkie rozkłady po prawej stronie równania (5) zastąpimy definicją rozkładu w przód i dokonamy wielu przekształceń, dostaniemy\n",
    "$$ q(x_{t-1} \\mid x_t, x_0) = \\mathcal{N}\\left(x_{t-1}; \n",
    "\\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} x_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t} x_0,\n",
    "\\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\beta_t \\mathbb{I}\n",
    "\\right). \\tag{6} $$ \n",
    "Ten wzór nie wygląda zbyt zachęcająco i ciężko zrozumieć co opisuje patrząc się na jego definicję. Warto natomiast pamiętać, że intuicyjnie chcemy dostać rozkład prawdopodobnych wersji mniej zaszumionego zdjęcia $x_t$.\n",
    "\n",
    "Mając wzór na posterior procesu w przód (6), definiujemy proces dyfuzyjny wstecz \n",
    "$$ p_\\theta(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)) \\tag{7}$$\n",
    "o wyuczalnych parametrach $\\theta$, który ma za zadanie jak najlepiej estymować (6). \n",
    "Proces wstecz zaczyna z rozkładu bazowego $p(x_T) = \\mathcal{N}(0, 1)$ i aplikuje T razy równanie (7), by otrzymać estymatę $x_0$. $\\mu_\\theta$ oraz $\\Sigma_theta$ to teoretyczne sieci neuronowe, odpowiedzialne za przewidywanie średnich i wariancji mniej zaszumionych $x_t$, natomiast takie rozwiązanie nie jest wykorzystywane w praktyce, a służy jedynie teoretycznym wyznaczeniom modelu. Jak się później okaże, w praktyce wystarczy nam jedna sieć do predykcji szumu zawartego w próbce $x_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcja straty\n",
    "Teoretyczną funkcją straty dla modelu dyfuzyjnego jest negatywny logarytm wiarygodności (negative log-likelihood). Nie jest on jednak policzalny z uwagi na zależność między kolejnymi krokami w procesie dyfuzji. W praktyce, wykorzystuje się zatem *Evidence Lower Bound* (ELBO),\n",
    "$$ \n",
    "- log(p_\\theta(x_0)) \\leq - log(p_\\theta(x_0)) + D_{KL}(q(x_{1:T} | x_0) || p_\\theta(x_{1:T}|x_0)). \\tag{8} \n",
    "$$\n",
    "Po bardzo długich przekształceniach otrzymujemy nierówność \n",
    "$$\n",
    "- log(p_\\theta(x_0)) \\leq \\sum_{t=1}^T D_{KL}(q(x_{t-1} | x_t, x_0) \\; || \\; p_\\theta(x_{t-1} | x_t)). \\tag{9}\n",
    "$$\n",
    "Zatem minimalizując dywergencję Kullbacka-Leiblera pomiędzy wyuczalnym procesem wstecz $p_\\theta$, a odpowiadającym posteriorem procesu w przód, minimalizujemy teoretyczny NLL. \n",
    "\n",
    "- Jak można zaobserwować z równań (6) i (7), oba te rozkłady są rozkładami Gaussa, a dywergencja KL pomiędzy dwoma Gaussami jest znana ([link](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Examples)).\n",
    "- Dodatkowo, warto zauważyć, że wariancja w (6) nie zależy od danych (brak $x_0$ czy też $x_t$ itp), co oznacza, że wariancja jest znana i nie trzeba jej optymalizować w procesie (7) - istotna jest jedynie średnia $\\mu_\\theta(x_t, t)$.\n",
    "\n",
    "Te obserwacje i szereg kolejnych obliczeń (pokazanych w [blogu](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)) doprowadza nas ostatecznie do bardzo podstawowej funkcji straty (MSE)\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{t=1}^T \\frac{(1 - \\alpha_t)^2}{2 \\alpha_t (1 - \\bar{\\alpha}_t) || \\Sigma ||_2^2} || \\epsilon_t - \n",
    "\\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_t, t) ||^2, \\tag{10}\n",
    "$$\n",
    "gdzie $\\epsilon_t$ to szum obecny w próbce $x_t$, którą chcemy odszumić, natomiast $\\epsilon_\\theta$ to model predykcji szumu, który dostaje próbkę $x_t$ zgodnie z wzorem (4) o szumie $\\epsilon_t$. \n",
    "Powyższy wzór można uprościć pozbywając się wyrazów wolnych, niezależnych od $\\theta$, co według [[2]](https://arxiv.org/pdf/2006.11239) poprawia stabilność modelu\n",
    "$$\n",
    "\\mathcal{L}_{ \\text{simple} } = \\sum_{t=1}^T || \\epsilon_t - \n",
    "\\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_t, t) ||^2. \\tag{11}\n",
    "$$\n",
    "\n",
    "W praktyce w trakcie treningu dla każdej próbki w batchu:\n",
    "- zamiast iterować po wszystkich krokach i sumować błąd, dla każdej próbki losujemy niezależnie jeden krok $t$\n",
    "- zaszumiamy $x_0$ do $x_t$ zgodnie z (4)\n",
    "- predykujemy szum obecny w $x_t$ i wyznaczamy MSE między rzeczywistym szumem $\\epsilon_t$, a wynikiem modelu $\\epsilon_\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowe materiały\n",
    "Materiały posegregowane wg ilości detali.\n",
    "- Video na temat dyfuzji: [youtube](https://www.youtube.com/watch?v=HoKDTa5jHvg)\n",
    "- Omówienie artykułu DDPM: [youtube](https://www.youtube.com/watch?v=W-O7AZNzbzQ)\n",
    "- Blog na temat dyfuzji: [blog](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from scipy.linalg import sqrtm  # noqa: E501 (funkcja przydatna w jednym z rozwiązań)\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import SmallDenoiserNetwork, LargeConvDenoiserNetwork, InceptionV3\n",
    "from src.datasets import MoonsDataset, CIFAR10Dataset\n",
    "from src.visuals import visual_comparison, plot_loss_curve, plot_trajectories, show_images, plot_image_trajectories\n",
    "from src.unittests import DDPMTests, DDIMTests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_SAMPLES = 5000 # definiujemy ile próbek ma znaleźć się w zbiorze danych, oraz ile chcemy generować przez model (dla porównania)\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "\n",
    "print(\"Używasz:\", DEVICE) # zalecane korzystanie z GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizujemy zbiór danych Moons (2D) z 1000 próbkami. Wizualizujemy wspomniany zbiór, porównując go do naszego rozkładu a priori - rozkładu normalnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MoonsDataset(NUMBER_OF_SAMPLES)\n",
    "prior = torch.randn(NUMBER_OF_SAMPLES, 2)\n",
    "\n",
    "visual_comparison(ds.samples(), prior, [\"Dane rzeczywiste\", \"Prior\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja `apply` to funkcja pomocnicza do przemnażania wartości *noise schedulera* ($\\beta$, $\\alpha$, $\\bar{\\alpha}$ itp) z wektorami z przestrzeni danych ($x_0$, $x_t$, $\\epsilon$ itp) o czasach dyfuzyjnych $t$. \n",
    "\n",
    "- Podając jako `coefficients` (na przykład $\\alpha$) podajemy wartości dla wszystkich możliwych kroków tzn $\\alpha_0, \\alpha_1, ..., \\alpha_T$.\n",
    "- `timesteps` to wektor kroków dyfuzyjnych, różnych dla każdej z próbek w batchu. Dla przykładu $t = [123, 500, 25, 740]$ stworzy sekwencje $[\\alpha_{123}, \\alpha_{500}, \\alpha_{25}, \\alpha_{740}]$, która zostanie przemnożona przez kolejne próbki w batchu $x$ tzn $[\\alpha_{123} \\cdot x^{(1)}, \\alpha_{500} \\cdot x^{(2)}, \\alpha_{25} \\cdot x^{(3)}, \\alpha_{740} \\cdot x^{(4)}]$\n",
    "\n",
    "Funkcja `apply` znacząco ułatwia zapis równań procesów dyfuzyjnych w kodzie i obsługuje jednoczesne przetwarzanie wielu próbek o różnych krokach dyfuzyjnych. Zanim przejdziesz dalej, upewnij się, że rozumiesz jej działanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(\n",
    "        coefficients: np.array, \n",
    "        timesteps: torch.tensor, \n",
    "        x: torch.tensor\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Wyznacza współczynniki z aktualnych kroków dyfuzyjnych i przemnaża je przez tensor x.\n",
    "\n",
    "    :param coefficients: 1D numpy array, wartości współczynników noise scheduler'a (np alpha, beta itp) dla wszystkich 1000 kroków\n",
    "    :param timesteps: 1D tensor, wartości kroków dyfuzjnych dla każdej z próbki w batchu\n",
    "    :param x: tensor, batch wartości z domeny danych (czystych bądź zaszumionych)\n",
    "    :return: tensor, wynik przemnożenia coefficients[t] * x. Wynik posiada taki sam rozmiar jak x.\n",
    "    \"\"\"\n",
    "    factors = torch.from_numpy(coefficients).to(device=timesteps.device)[timesteps].float() \n",
    "    K = x.dim() - 1 # ilość osi w x (minus 1 bo nie liczymy batch size), dla danych Moons jest to 1, dla obrazów jest to 3 (kanał, szerokość, wysokość)\n",
    "    factors = factors.view(-1, *([1]*K)).expand(x.shape) # tworzymy puste osie, żeby można przemnożyć mnożniki przez x\n",
    "    return factors * x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1 (2 punkty)\n",
    "Korzystając z wartości `betas`, `alphas`, `alphas_bar`, `alphas_bar_prev`, a także funkcji `apply` zaimplementuj:\n",
    "- metodę `q_sample`, która reprezentuje proces w przód (zaszumianie danych). Na podstawie $x_0$, $t$ i $\\epsilon$ zwraca $x_t$ zgodnie z (4),\n",
    "- metodę `q_posterior`, która reprezentuje posterior procesu w przód z równania (6) (odszumianie danych),\n",
    "- metodę `train_step`, która dla batcha zdjęć $x_0$ zwróci uproszczoną funkcję straty (11) dla losowych $t$. Upewnij się, że **nie** używasz tego samego $t$ dla wszystkich próbek w batchu.\n",
    "\n",
    "**Uwaga**: Pamiętaj, żeby nigdzie nie definiować na sztywno wymiarowości danych (np. podczas generowania szumu). Zamiast tego, powinno się odwoływać do kształtu wejść (np. torch.randn_like(x)). Dzięki temu klasa dyfuzji będzie działać dla dowolnych danych (co później zostanie zademonstrowane na przykładzie zbioru CIFAR). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"\n",
    "    Podstawowa klasa architektury DDPM. \n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps=1000):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.timesteps = list(range(self.num_timesteps))[::-1]\n",
    "\n",
    "        self.betas = np.linspace(start=0.0001, stop=0.02, num=self.num_timesteps)\n",
    "        self.setup_noise_scheduler(self.betas)\n",
    "\n",
    "    def setup_noise_scheduler(self, betas):\n",
    "        self.alphas = 1.0 - betas\n",
    "        self.alpha_bars = np.cumprod(self.alphas, axis=0)\n",
    "        self.alpha_bars_prev = np.append(1.0, self.alpha_bars[:-1])\n",
    "\n",
    "    def q_sample(self, x_0, t, noise=None):\n",
    "        \"\"\"\n",
    "        próbkowanie z rozkładu q(x_t | x_0). dodaje szum do próbki x_0 o sile zgodnie ze znacznikiem czasowym t.\n",
    "\n",
    "        :x_0: batch czystych próbek do zaszumienia\n",
    "        :t: wektor znaczników czasowych. Każda próbka ma swój niezależny czas.\n",
    "        :noise: Szum nakładany na próbkę x_0, przeskalowany zgodnie z wartościami schedulera. \n",
    "                Gdy szum nie został podany, jest on próbkowany z rozkładu Gaussa\n",
    "        :return: x_t - batch zaszumionych próbek x_0 do chwili czasowej t\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "\n",
    "        # POCZĄTEK ROZWIĄZANIA\n",
    "        raise NotImplementedError(\"Nie zaimplementowano funkcji\")\n",
    "        # KONIEC ROZWIĄZANIA\n",
    "\n",
    "    def q_posterior(self, x_t, x_0, t, noise=None):\n",
    "        \"\"\"\n",
    "        próbkowanie z rozkładu q(x_{t-1} | x_t, x_0). Usuwa część szumu, modelując jak powinna wyglądać próbka x_{t-1}, by x_t była prawdopodobna.\n",
    "\n",
    "        :x_t: batch zaszumionych próbek w chwili t\n",
    "        :x_0: batch czystych próbek \n",
    "        :t: wektor znaczników czasowych. Każda próbka ma swój niezależny czas.\n",
    "        :noise: szum służący do wypróbkowania konkretnego x_{t-1} z rozkładu a posteriori, które ma rozkład Gaussa.\n",
    "        :return: x_{t-1} - batch delikatnie odszumionych próbek w chwili czasowej t-1. \n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "\n",
    "        # POCZĄTEK ROZWIĄZANIA\n",
    "        raise NotImplementedError(\"Nie zaimplementowano funkcji\")\n",
    "        # KONIEC ROZWIĄZANIA\n",
    "\n",
    "    def _predict_x_0_from_eps(self, x_t, t, eps):\n",
    "        \"\"\"\n",
    "        Estymuje x_0 na bazie zaszumionych próbek x_t, szumu jaki się w nich znajduje eps, oraz znacznika czasowego t. \n",
    "        Można łatwo wyznaczyć ten wzór przekształcając wzór (4) (stosując sztuczkę z reparametryzacją).\n",
    "\n",
    "        :x_t: zaszumione próbki x_t\n",
    "        :t: znaczniki czasowe. Różne dla innych próbek w batchu\n",
    "        :eps: szum obecny w x_t\n",
    "        :return: próbki x_0 stworzone poprzez usunięcie szumu eps z próbek x_t.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            apply(np.sqrt(1.0 / self.alpha_bars), t, x_t) - \n",
    "            apply(np.sqrt(1.0 / self.alpha_bars - 1.0), t, eps)\n",
    "        )\n",
    "\n",
    "    def _predict_eps_from_xstart(self, x_t, t, x_0):\n",
    "        \"\"\"\n",
    "        Estymuje szum w próbce x_t na bazie zaszumionych próbek x_t, czystych zdjęć x_0, oraz znacznika czasowego t. \n",
    "        Można łatwo wyznaczyć ten wzór przekształcając wzór (4) (stosując sztuczkę z reparametryzacją).\n",
    "\n",
    "        :x_t: zaszumione próbki x_t\n",
    "        :t: znaczniki czasowe. Różne dla innych próbek w batchu\n",
    "        :x_0: Czyste próbki, bądź estymaty czystych próbek.\n",
    "        :return: próbki x_0 stworzone poprzez usunięcie szumu eps z próbek x_t.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            apply(np.sqrt(1.0 / self.alpha_bars), t, x_t) - x_0\n",
    "        ) / apply(np.sqrt(1.0 / self.alpha_bars - 1.0), t, torch.ones_like(x_t))\n",
    "\n",
    "    def train_losses(self, model, x_0):\n",
    "        \"\"\"\n",
    "        Funkcja która zwraca wartość funkcji straty z wzoru (11) dla pewnego batcha czystych próbek x_0 oraz modelu.\n",
    "        Funkcja próbkuje losowe znaczniki czasowe, oraz szum aplikowany do danych x_0. \n",
    "        Następnie za pomocą q_sample tworzy zaszumione dane x_t zgodnie z definicją procesu w przód.\n",
    "        Model predykuje wartość szumu na podstawie danych x_t oraz znacznika t. \n",
    "        Ostateczny wynik to MSE pomiędzy prawdziwym (wcześniej wypróbkowanym) szumem, a tym wypredykowanym przez model\n",
    "\n",
    "        :model: odszumiająca sieć neuronowa, której rolą jest predykować szum \n",
    "        :x_0: Prawdziwe dane, na których uczymy model. \n",
    "        :return: wartość błedu średniokwadratowego pomiędzy prawdziwym a predykowanym szumem Gaussowskim\n",
    "        \"\"\"\n",
    "        # POCZĄTEK ROZWIĄZANIA\n",
    "        loss = 0\n",
    "        raise NotImplementedError(\"Nie zaimplementowano funkcji\")\n",
    "        # KONIEC ROZWIĄZANIA\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        noise: torch.tensor, \n",
    "        num_inference_steps: int = 1000,\n",
    "        return_trajectory: bool = False, \n",
    "        clip: bool = False,\n",
    "        quiet: bool = True\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Proces dyfuzyjny wstecz służący do generowania nowych próbek. \n",
    "        Proces ten zaczyna się na czystym szumie, który jest wielokrotnie poddawany stopniowemu\n",
    "        odszumianiu z wykorzystaniem sieci neuronowej. \n",
    "\n",
    "        :model: sieć neuronowa predykująca szum. Na podstawie jej wyników dokonywane jest generowanie danych\n",
    "        :noise: szum startowy. Wygenerowanie dane będą posiadały dokładnie ten sam wymiar\n",
    "        :num_inference_steps: Ilość kroków dyfuzyjnych w procesie próbkowania. Im więcej tym lepsze wyniki modelu, ale wolniejsza inferencja\n",
    "        :return_trajectory: czy zwracać wyniki kroków pośrednich x_t dla wszystkich 1000 kroków (dla celów wizualizacyjnych)\n",
    "        :clip: Czy aplikować clip do przedziału danych na estymaty x_0 w każdym kroku. Szczególnie użyteczne dla zdjęć.\n",
    "        :quiet: czy nie wyświetlać paska postępu\n",
    "\n",
    "        :return: ostateczne próbki jako macierz numpy. Gdy return_trajectory jest True - dodatkowo sekwencje x_t\n",
    "        \"\"\"\n",
    "        self._respace(num_timesteps=num_inference_steps)\n",
    "\n",
    "        x_t = noise\n",
    "        bsz = x_t.shape[0]\n",
    "        trajectory = [x_t.clone().cpu()]\n",
    "\n",
    "        # iterujemy zaczynając od T i zmniejszając kroki aż do 0\n",
    "        pbar = tqdm(enumerate(self.timesteps), desc='Próbkowanie', total=self.num_timesteps) if not quiet else enumerate(self.timesteps)\n",
    "\n",
    "        for idx, time in pbar:\n",
    "            t = torch.tensor([time] * bsz, device=x_t.device).long()\n",
    "            i = torch.tensor([self.num_timesteps - idx - 1] * bsz, device=x_t.device).long()\n",
    "\n",
    "            # próbkuj szum poprzez model i wyznacz estymatę x_0 \n",
    "            eps = model(x_t, t)\n",
    "            x_0 = self._predict_x_0_from_eps(x_t, i, eps)\n",
    "\n",
    "            # W sytuacji kiedy model operuje na zdjęciach, często normalizujemy zdjęcia do przedziału (-1,1)\n",
    "            # Gdy w każdym kroku clipujemy estymację czystej próbki x_0 do tego samego przedziału zwiększa to stabilność modelu\n",
    "            if clip:\n",
    "                x_0 = x_0.clamp(-1, 1)\n",
    "\n",
    "            # krok odszumiający przy wykorzystaniu wzoru na posterior procesu w przód\n",
    "            x_t = self.q_posterior(x_t, x_0, i)\n",
    "\n",
    "            # dodanie x_t do celów wizualizacyjnych (nie ma wpływu na działanie metody)\n",
    "            trajectory.append(x_t.clone().cpu())\n",
    "\n",
    "        self._respace(1000) # na koniec wracamy do domyślnych 1000 kroków\n",
    "\n",
    "        if return_trajectory:\n",
    "            return x_0.cpu().numpy(), torch.stack(trajectory, dim=0).numpy()\n",
    "        return x_0.cpu().numpy()\n",
    "    \n",
    "    def _respace(self, num_timesteps):\n",
    "        \"\"\"\n",
    "        Funkcja zmieniająca ilość kroków dyfuzyjnych w inferencji. \n",
    "        Redukcja kroków wiąże się z szybszą inferencją kosztem gorszej jakości.\n",
    "        Wartości noise scheduler'a muszą zostać dopasowane, ponieważ różnice pomiędzy x_{t-1} a x_t ulegają zmianie\n",
    "\n",
    "        :num_timesteps: nowa ilość kroków dyfuzyjnych.\n",
    "        \"\"\"\n",
    "        betas = np.linspace(start=0.0001, stop=0.02, num=1000)\n",
    "        self.setup_noise_scheduler(betas) \n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.timesteps = np.linspace(999, 0, self.num_timesteps, dtype=int, endpoint=True)\n",
    "\n",
    "        last_alpha_cumprod = 1.0\n",
    "\n",
    "        self.betas = []\n",
    "\n",
    "        for i, alpha_bar in enumerate(self.alpha_bars):\n",
    "            if i in self.timesteps:\n",
    "                self.betas.append(1 - alpha_bar / last_alpha_cumprod)\n",
    "                last_alpha_cumprod = alpha_bar\n",
    "        \n",
    "        self.betas = np.array(self.betas)\n",
    "        self.setup_noise_scheduler(self.betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja procesu dyfuzji w przód\n",
    "Dla coraz większych kroków, ustrukturyzowane dane powinny stopniowo zmieniać się w czysty szum Gaussa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = GaussianDiffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_tests = DDPMTests(diffusion, DEVICE)\n",
    "ddpm_tests.run_tests()\n",
    "print(\"Wszystkie testy przeszły pomyślnie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = ds.samples()\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "plt.subplot(1, 6, 1)\n",
    "plt.scatter(x_0[:1000, 0], x_0[:1000, 1], s=7)\n",
    "plt.xlim(-4, 4)\n",
    "plt.ylim(-4, 4)\n",
    "plt.title(\"czas t=0\")\n",
    "\n",
    "for i, t in enumerate([40, 100, 500, 999]):\n",
    "    plt.subplot(1, 6, i + 2)\n",
    "    x_t = diffusion.q_sample(x_0, torch.tensor([t] * NUMBER_OF_SAMPLES))\n",
    "    plt.scatter(x_t[:1000, 0], x_t[:1000, 1], s=7)\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.title(f\"czas t={t}\")\n",
    "\n",
    "plt.subplot(1, 6, 6)\n",
    "plt.scatter(prior[:1000, 0], prior[:1000, 1], s=7)\n",
    "plt.xlim(-4, 4)\n",
    "plt.ylim(-4, 4)\n",
    "plt.title(\"Prior (czysty Gauss)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymany wynik powinien przypominać:\n",
    "\n",
    "![example](imgs/forward_diffusion_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening modelu dyfuzyjnego\n",
    "Korzystając z zaimplementowanej przez Ciebie klasy dyfuzyjnej wytrenujmy prosty model (sieć MLP) na zbiorze danych Moons. Sieć na wejściu posiada trzy neurony (pozycja próbki na osi x, pozycja próbki na osi y, oraz krok dyfuzyjny $t$), na wyjściu sieć zwraca dwa neurony odpowiadające szumowi zaaplikowanymi na każdy z dwóch wymiarów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_moons = SmallDenoiserNetwork().to(DEVICE)\n",
    "ds = MoonsDataset(NUMBER_OF_SAMPLES)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=5000, shuffle=True)\n",
    "\n",
    "ddpm = GaussianDiffusion()\n",
    "\n",
    "optimizer = torch.optim.Adam(model_moons.parameters(), lr=5e-3)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "pbar = tqdm(range(EPOCHS), desc='Trening')\n",
    "for i in pbar:\n",
    "    epoch_loss = []\n",
    "    for x in dl:\n",
    "        optimizer.zero_grad()\n",
    "        loss = ddpm.train_losses(model_moons, x.to(DEVICE))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    loss_values.append(sum(epoch_loss) / len(epoch_loss))\n",
    "    pbar.set_postfix({'loss': loss_values[-1]})\n",
    "\n",
    "ddpm_tests.assess_loss(loss_values)\n",
    "\n",
    "samples, trajectories = ddpm.p_sample_loop(model_moons, torch.randn(NUMBER_OF_SAMPLES, 2, device=DEVICE), return_trajectory=True, quiet=False)\n",
    "\n",
    "plot_loss_curve(loss_values)\n",
    "visual_comparison(ds.samples(), samples, [\"Dane rzeczywiste\", \"Wygenerowane przez model\"])\n",
    "plot_trajectories(ds, trajectories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministyczne próbkowanie (DDIM, Denoising Diffusion Implicit Model)\n",
    "Klasyczne modele dyfuzyjne wprowadzone w [[1](https://arxiv.org/pdf/1503.03585), [2](https://arxiv.org/pdf/2006.11239)] doczekały się wielu usprawnień w szeregu kolejnych publikacji [[3](https://arxiv.org/pdf/2010.02502), [4](https://arxiv.org/pdf/2206.00364), [5](https://arxiv.org/pdf/2210.02747)]. \n",
    "DDIM [[3](https://arxiv.org/pdf/2010.02502)] usprawnia proces próbkowania pozbywając się losowości we wzorze na posterior procesu w przód i traktując pojedynczy krok dyfuzyjny jako interpolacje pomiędzy $x_t$, a wstępną predykcją $x_0$. Tak zdefiniowany nowy posterior jest rozkładem jednopunktowym i wyraża się wzorem \n",
    "$$\n",
    "q(x_{t-1} | x_t, x_0) = \\sqrt{\\bar{\\alpha}_{t-1}} x_0 + \\sqrt{1 - \\bar{\\alpha}_{t-1}} \\frac{x_t - \\sqrt{\\bar{\\alpha}_t}x_0}{\\sqrt{1 - \\bar{\\alpha}_t}} \\tag{12}\n",
    "$$\n",
    "\n",
    "Warto jednak zwrócić uwagę, że mimo, że posterior jest deterministyczny, to startujemy wciąż z rozkładu bazowego $\\mathcal{N}(0, 1)$ co daje nam możliwość generowania losowych próbek. Dodatkowo, zwróć uwagę, że zmianie ulega tutaj tylko sposób próbkowania, a nie samego trenowania modelu, dzięki czemu nie musimy trenować nowej sieci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2 (1.5 punkta)\n",
    "- Wzór (12) można zapisać w inny, bardziej zrozumiały sposób. W tym celu podstaw pod $x_t$ wzór (4) stosując sztuczkę z reparametryzacją (szum obecny w $x_t$ nazwij $\\epsilon_t$). Uprość wzór maksymalnie i zapisz wnioski, porównując otrzymany wynik do wzoru (4).\n",
    "- Zaimplementuj posterior DDIM zgodnie z otrzymanym równaniem. W celu ekstrakcji szumu $\\epsilon_t$ obecnego w próbce $x_t$ użyj metody `self._predict_eps_from_xstart(x_t, t, x_0)` obecnej w klasie `GaussianDiffusion`. Zwizualizuj wyniki nowej metody próbkującej (korzystając z gotowej komórki poniżej) i napisz wnioski co uległo zmianie, a co jest podobnie w stosunku do DDPM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu wyprowadź wzór i zapisz wnioski ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicGaussianDiffusion(GaussianDiffusion):\n",
    "    def q_posterior(self, x_t, x_0, t):\n",
    "        \"\"\"\n",
    "        próbkowanie z rozkładu q(x_{t-1} | x_t, x_0) korzystając z metody DDIM.\n",
    "        Usuwa część szumu, interpolując pomiędzy x_t a x_0\n",
    "\n",
    "        :x_t: batch zaszumionych próbek w chwili t\n",
    "        :x_0: batch czystych próbek \n",
    "        :t: wektor znaczników czasowych. Każda próbka ma swój niezależny czas.\n",
    "        :noise: szum służący do wypróbkowania konkretnego x_{t-1} z rozkładu a posteriori, które ma rozkład Gaussa.\n",
    "        :return: x_{t-1} - batch delikatnie odszumionych próbek w chwili czasowej t-1. \n",
    "        \"\"\"\n",
    "\n",
    "        # POCZĄTEK ROZWIĄZANIA\n",
    "        raise NotImplementedError(\"Nie zaimplementowano funkcji\")\n",
    "        # KONIEC ROZWIĄZANIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim = DeterministicGaussianDiffusion()\n",
    "\n",
    "ddim_tests = DDIMTests(ddim, DEVICE)\n",
    "ddim_tests.run_tests()\n",
    "print(\"Wszystkie testy przeszły pomyślnie!\")\n",
    "\n",
    "samples, trajectories = ddim.p_sample_loop(model_moons, torch.randn(NUMBER_OF_SAMPLES, 2, device=DEVICE), return_trajectory=True, quiet=False)\n",
    "visual_comparison(ds.samples(), samples, [\"Dane rzeczywiste\", \"Wygenerowane przez model\"])\n",
    "plot_trajectories(ds, trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tu napisz wnioski i porównanie trajektorii DDIM z DDPM:* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dyfuzja na obrazach\n",
    "Powyżej rozpatrywaliśmy bardzo prosty zbiór danych, posiadający tylko dwa wymiary. Modele dyfuzyjne bardzo dobrze skalują się jednak na bardziej złożone modalności. Poniżej będziemy operować na zbiorze danych CIFAR10, posiadającym obrazy przedstawiające obiekty 10 klas. Zdjęcia z tego zbioru są w rozdzielczości $32 \\times 32$ i są w formacie RGB, co daje $32 \\times 32 \\times 3 = 3072$ wymiary. Wraz ze zwiększeniem zbioru danych musimy także zwiększyć nasz model predykcji szumu - zamiast prostej MLP będziemy korzystać z sieci U-Net, która idealnie nadaje się do przetwarzania obrazów. Dość duży U-Net został przez nas wcześniej wytrenowany na zbiorze CIFAR i jest gotowy do użycia przy próbkowaniu nowych zdjęć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('checkpoints/best.pth'):\n",
    "    url = \"https://drive.google.com/uc?id=1BfgADqMLzgFLq7uvhuLLO6u9RFS99uND\"\n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "    gdown.download(url, 'checkpoints/best.pth') \n",
    "\n",
    "model_cifar = LargeConvDenoiserNetwork()\n",
    "model_cifar.load_state_dict(torch.load('checkpoints/best.pth', map_location='cpu'))\n",
    "model_cifar.to(DEVICE)\n",
    "\n",
    "image_ds = CIFAR10Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 48\n",
    "# wypróbkujmy N zdjęć ze zbioru CIFAR \n",
    "real = torch.stack([image_ds[i] for i in range(N)]).numpy()\n",
    "\n",
    "# wypróbkujmy N zdjec przy uzyciu modelu i dyfuzji DDPM\n",
    "generated_ddpm, traj_ddpm = ddpm.p_sample_loop(model_cifar, noise=torch.randn(N, 3, 32, 32, device=DEVICE), return_trajectory=True, clip=True, quiet=False)\n",
    "\n",
    "# wypróbkujmy N zdjec przy uzyciu modelu i dyfuzji DDIM\n",
    "generated_ddim, traj_ddim = ddim.p_sample_loop(model_cifar, noise=torch.randn(N, 3, 32, 32, device=DEVICE), return_trajectory=True, clip=True, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(real, generated_ddpm, generated_ddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_trajectories(traj_ddpm, traj_ddim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryki modeli generatywnych\n",
    "Modele dyfuzyjne, jak i inne modele generatywne (Generatywne sieci przeciwstawne, Autokodery Wariacyjne, Normalizujące sieci przepływowe itp) potrafią generować nowe próbki danych bez jakichkolwiek informacji wejściowych. Z tego powodu, wygenerowane próbki nie posiadają swojego ground truth do którego możemy porównać nasze predykcje. Jak zatem ocenić jakość modelu, by być w stanie porównywać ze sobą różne architektury?\n",
    "\n",
    "### FID\n",
    "Postawione powyżej pytanie jest wciąż pytaniem otwartym, ponieważ nie istnieje idealna metryka dla modeli czysto generatywnych. Najbardziej popularną metryką jest FID (Frechet Inception Distance). Oto mechanizm jej działania:\n",
    "- Pobieramy reprezentatywną próbę prawdziwych danych (np. $5000$ zdjęć ze zbioru CIFAR). Od ilości rozpatrywanych danych bierze się pełna nazwa metryki (np. FID-5k dla $5000$ próbek, lub FID-10k dla $10000$ próbek)*.\n",
    "- Korzystając z wyuczonego modelu generatwynego próbkujemy tyle samo sztucznych zdjęć.\n",
    "- Następnie, używając *innej* wytrenowanej sieci na podobnych danych (np. jakiegoś autokodera, lub klasyfikatora bez ostatniej warstwy) jako ekstraktora cech, osadzamy wszystkie zdjęcia prawdziwe i sztuczne do przestrzeni ukrytej.\n",
    "- W przestrzeni ukrytej estymujemy dwa rozkłady Gaussa: osobno dla danych prawdziwych, oraz dla danych wygenerowanych przez nasz model generatywny.\n",
    "- Porównujemy odległość dwóch Gaussów za pomocą odległości Wassersteina o wzorze\n",
    "$$ d_{F}(\\mathcal N(\\mu, \\Sigma), \\mathcal N(\\mu', \\Sigma'))^2 = \\lVert \\mu - \\mu' \\rVert^2_2 + \\operatorname{tr}\\left(\\Sigma + \\Sigma' -2\\left(\\Sigma \\Sigma'  \\right)^\\frac{1}{2} \\right) \\tag{13}$$ \n",
    "\n",
    "\\* - *im więcej próbek, tym dokładniejsza metryka, lecz jej obliczenie trwa dłużej i potrzeba więcej danych testowych*.\n",
    "\n",
    "### Zadanie 3 (1.5 punkta)\n",
    "Zaimplementuj metrykę FID i wyznacz wartość FID-1k dla modelu `model_cifar` przy użyciu metod próbkujących DDPM i DDIM oraz różnej liczby kroków. Twoim zadaniem jest:\n",
    "- implementacja funkcji `embed_generated_data`, która wypróbkuje 1000 zdjęć przy użyciu wytrenowanego modelu dyfuzyjnego, a następnie osadzi zdjęcia do przestrzeni ukrytej za pomocą sieci `inception_net`.\n",
    "- implementacja funkcji `fit_n_dimensional_gaussian`, która dopasowywuje 2048-wymiarowego Gaussa (to jest rozmiar przestrzeni ukrytej ekstraktora cech) do 1000 osadzonych zdjęć\n",
    "- implementacja fukcji `wasserstein_distance`, która liczy odległość Wassersteina dla dwóch Gaussów zgodnie ze wzorem (13).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_SAMPLE_SIZE = 1_000\n",
    "batch_size = 250 # można zwiększyć/zmniejszyć w zależności od posiadanej pamięci GPU\n",
    "iterations = math.ceil(FID_SAMPLE_SIZE / batch_size)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_real_data(ds, inception_net):\n",
    "    real_latents = []\n",
    "\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "    for x in tqdm(dl, desc=\"Osadzanie\", total=iterations):\n",
    "        if len(real_latents)*batch_size >= FID_SAMPLE_SIZE:\n",
    "            real_latents = real_latents[:FID_SAMPLE_SIZE]\n",
    "            break\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        z = inception_net(x)\n",
    "        real_latents.append(z)\n",
    "\n",
    "\n",
    "    real_latents = torch.cat(real_latents, dim=0).numpy()\n",
    "    return real_latents\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_generated_data(model, sampler, num_timesteps, inception_net):\n",
    "    \"\"\"\n",
    "    Funkcja generująca próbki za pomocą modelu (sieć odszumiająca) i samplera (DDPM bądź DDIM) i osadzająca je w przestrzeni ukrytej modelu inception_net\n",
    "\n",
    "    :model: sieć odszumiająca, której rolą jest generowanie danych\n",
    "    :sampler: sampler (DDPM bądź DDIM) który generuje dane zgodnie z procesem odwrotnym\n",
    "    :num_timesteps: liczba kroków dyfuzyjnych w procesie generowania\n",
    "    :inception_net: sieć, która osadza dane w przestrzeni ukrytej\n",
    "\n",
    "    :return: osadzone dane w przestrzeni ukrytej\n",
    "    \"\"\"\n",
    "    fake_latents = []\n",
    "\n",
    "    # POCZĄTEK ROZWIĄZANIA\n",
    "    raise NotImplementedError(\"Nie zaimplementowano funkcji\")\n",
    "    # KONIEC ROZWIĄZANIA\n",
    "\n",
    "    return fake_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_net = InceptionV3(normalize_input=False).to(DEVICE)\n",
    "TIMESTEPS = [3, 10, 30, 50]\n",
    "\n",
    "real_latents = embed_real_data(image_ds, inception_net)\n",
    "\n",
    "ddpm_latents = []\n",
    "ddim_latents = []\n",
    "\n",
    "for steps in tqdm(TIMESTEPS, desc=\"Generowanie i osadzanie wygenerowanych zdjęć\", total=len(TIMESTEPS)):\n",
    "    ddpm_latents.append(\n",
    "        embed_generated_data(\n",
    "            model=model_cifar, \n",
    "            sampler=ddpm, \n",
    "            num_timesteps=steps, \n",
    "            inception_net=inception_net\n",
    "        ) \n",
    "    )\n",
    "\n",
    "    ddim_latents.append(\n",
    "        embed_generated_data(\n",
    "            model=model_cifar, \n",
    "            sampler=ddim, \n",
    "            num_timesteps=steps, \n",
    "            inception_net=inception_net\n",
    "        ) \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_n_dimensional_gaussian(latents):\n",
    "    \"\"\"\n",
    "    Funkcja dopasowująca rozkład Gaussa o parametrach średniej mu i macierzy kowariancji sigma do danych w przestrzeni ukrytej \n",
    "\n",
    "    :latents: dane w przestrzeni ukrytej, dla których dopasowujemy rozkład Gaussa\n",
    "\n",
    "    :return: mu, sigma - parametry rozkładu Gaussa - wektor średniej i macierz kowariancji\n",
    "    \"\"\"\n",
    "    # POCZĄTEK ROZWIĄZANIA\n",
    "    mu, sigma = None, None\n",
    "    raise NotImplementedError(\"Nie zaimplementowano funkcji\")\n",
    "    # KONIEC ROZWIĄZANIA\n",
    "    return mu, sigma\n",
    "\n",
    "\n",
    "def wasserstein_distance(mu1, sigma1, mu2, sigma2):\n",
    "    \"\"\"\n",
    "    Funkcja wyznaczająca odległość Wassersteina pomiędzy dwoma rozkładami Gaussa o parametrach mu i sigma\n",
    "\n",
    "    :mu1: średnia pierwszego rozkładu\n",
    "    :sigma1: macierz kowariancji pierwszego rozkładu\n",
    "    :mu2: średnia drugiego rozkładu\n",
    "    :sigma2: macierz kowariancji drugiego rozkładu\n",
    "    \"\"\"\n",
    "    # POCZĄTEK ROZWIĄZANIA\n",
    "    distance = 0\n",
    "    raise NotImplementedError(\"Nie zaimplementowano funkcji\")\n",
    "    # KONIEC ROZWIĄZANIA\n",
    "\n",
    "    return distance.real # błąd numeryczny może sprawić, że wynik jest zespolony, dlatego interesuje nas tylko rzeczywista część"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mu, real_sigma = fit_n_dimensional_gaussian(real_latents)\n",
    "\n",
    "ddpm_fid = []\n",
    "ddim_fid = []\n",
    "\n",
    "for ddpm_vals in tqdm(ddpm_latents, desc='Wyznaczanie FID dla DDPM'):\n",
    "    fake_mu, fake_sigma = fit_n_dimensional_gaussian(ddpm_vals)\n",
    "    FID = wasserstein_distance(real_mu, real_sigma, fake_mu, fake_sigma)\n",
    "    ddpm_fid.append(FID)\n",
    "\n",
    "for ddim_vals in tqdm(ddim_latents, desc='Wyznaczanie FID dla DDIM'):\n",
    "    fake_mu, fake_sigma = fit_n_dimensional_gaussian(ddim_vals)\n",
    "    FID = wasserstein_distance(real_mu, real_sigma, fake_mu, fake_sigma)\n",
    "    ddim_fid.append(FID)\n",
    "\n",
    "plt.plot(TIMESTEPS, ddpm_fid, label='DDPM', color='red', marker='X')\n",
    "plt.plot(TIMESTEPS, ddim_fid, label='DDIM', color='blue', marker='X')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Jakość dyfuzji w zależności od ilości kroków i metody próbkowania\")\n",
    "plt.xlabel('Ilość kroków dyfuzyjnych')\n",
    "plt.ylabel('Wartości FID')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zwróć uwagę, że FID opisuje nam dystans (między dwoma Gaussami), więc zależy nam na jej minimalizacji, ponieważ im FID jest mniejsze, tym mniejsza różnica w rozkładach danych prawdziwych oraz wygenerowanych.\n",
    "- Dyfuzja charakteryzuje się tym, że im więcej kroków zrobimy w walidacji, tym lepszej jakości dostaniemy wyniki, co pokrywa się z obserwacją, że FID maleje wraz ze zwiększaniem liczby kroków.\n",
    "- DDIM działa nieco lepiej niż DDPM w tym przypadku.\n",
    "- Osiągane tutaj wartości FID rzędu 38 są dość kiepskie porównując się z metodami state-of-the-art, a mimo to wygenerowane zdjęcia nie są aż takie złe :) Dużo lepsze wartości możnaby osiągnąć poprzez warunkowanie sieci konkretną klasą (one-hot z 10 klas)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
